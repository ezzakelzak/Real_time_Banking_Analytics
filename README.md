# ğŸ¦ Banking Modern Data Stack

![Snowflake](https://img.shields.io/badge/Snowflake-29B5E8?logo=snowflake&logoColor=white)
![DBT](https://img.shields.io/badge/dbt-FF694B?logo=dbt&logoColor=white)
![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?logo=apacheairflow&logoColor=white)
![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-231F20?logo=apachekafka&logoColor=white)
![Debezium](https://img.shields.io/badge/Debezium-EF3B2D?logo=apache&logoColor=white)
![Python](https://img.shields.io/badge/Python-3776AB?logo=python&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?logo=docker&logoColor=white)
![Power BI](https://img.shields.io/badge/Power%20BI-F2C811?logo=powerbi&logoColor=white)
![Git](https://img.shields.io/badge/Git-F05032?logo=git&logoColor=white)



---

ğŸ“Œ PrÃ©sentation du projet

Ce projet illustre une pipeline de donnÃ©es moderne de bout en bout appliquÃ©e au secteur bancaire.
Il simule des donnÃ©es de clients, de comptes et de transactions, diffuse les changements en temps rÃ©el, transforme ces donnÃ©es en modÃ¨les prÃªts pour lâ€™analyse, et visualise les rÃ©sultats â€” en suivant les bonnes pratiques de CI/CD et de data warehousing.

ğŸ‘‰ En rÃ©sumÃ©, câ€™est un Ã©cosystÃ¨me de donnÃ©es bancaires complet construit avec des outils modernes.



ğŸ—ï¸ Architecture
<img src="images/architecture.png" alt="Architecture" width="800"/>

Flux de la pipeline :

GÃ©nÃ©rateur de donnÃ©es â†’ Simule les transactions, comptes et clients bancaires (via Faker).

Kafka + Debezium â†’ Diffuse les changements en temps rÃ©el (CDC) vers MinIO (stockage compatible S3).

Airflow â†’ Orchestre lâ€™ingestion et les snapshots vers Snowflake.

Snowflake â†’ EntrepÃ´t de donnÃ©es Cloud (Bronze â†’ Silver â†’ Gold).

DBT â†’ Effectue les transformations et construit les marts & snapshots (SCD Type-2).

Power BI â†’  CrÃ©ation du Dashboard

âš¡ Stack technologique

Snowflake â†’ EntrepÃ´t de donnÃ©es cloud

DBT â†’ Transformations, tests, snapshots (SCD Type-2)

Apache Airflow â†’ Orchestration & planification de DAGs

Apache Kafka + Debezium â†’ Streaming temps rÃ©el & CDC

MinIO â†’ Stockage dâ€™objets compatible S3

PostgreSQL â†’ Base de donnÃ©es source (OLTP)

Python (Faker) â†’ GÃ©nÃ©ration de donnÃ©es simulÃ©es

Docker & docker-compose â†’ Environnement containerisÃ©



âœ… FonctionnalitÃ©s principales

PostgreSQL OLTP : Base transactionnelle respectant les contraintes ACID (clients, comptes, transactions)

SystÃ¨me bancaire simulÃ© : clients, comptes et opÃ©rations bancaires

Capture de changement de donnÃ©es (CDC) via Kafka + Debezium (lecture du WAL de Postgres)

ModÃ¨les DBT : Raw â†’ Staging â†’ Faits & Dimensions

Snapshots : suivi historique des donnÃ©es (slowly changing dimensions)

Orchestration automatique avec Airflow



ğŸ“‚ Structure du dÃ©pÃ´t
banking-modern-datastack/
         
â”œâ”€â”€ banking_dbt/              # Projet DBT
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/           # ModÃ¨les de staging
â”‚   â”‚   â”œâ”€â”€ marts/             # Tables de faits & dimensions
â”‚   â”‚   â””â”€â”€ sources.yml
â”‚   â”œâ”€â”€ snapshots/             # Snapshots SCD2
â”‚   â””â”€â”€ dbt_project.yml
â”œâ”€â”€ consumer
â”‚   â””â”€â”€ kafka_to_minio.py
â”œâ”€â”€ data-generator/            # GÃ©nÃ©rateur de donnÃ©es avec Faker
â”‚   â””â”€â”€ faker_generator.py
â”œâ”€â”€ docker/                    # DAGs Airflow, plugins, etc.
â”‚   â”œâ”€â”€ dags/                  # DAGs (minio_to_snowflake, scd_snapshots)
â”œâ”€â”€ kafka-debezium/            # Connecteurs Kafka & logique CDC
â”‚   â””â”€â”€ generate_and_post_connector.py
â”œâ”€â”€ postgres/                  # SchÃ©ma Postgres (DDL & seeds)
â”‚   â””â”€â”€ schema.sql
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml         # Infrastructure containerisÃ©e
â”œâ”€â”€ dockerfile-airflow.dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

âš™ï¸ Mise en Å“uvre Ã©tape par Ã©tape
1. Simulation des donnÃ©es

GÃ©nÃ©ration de donnÃ©es bancaires synthÃ©tiques (clients, comptes, transactions) avec Faker.

Insertion dans PostgreSQL (OLTP) pour simuler un vrai systÃ¨me transactionnel (ACID, contraintes).

Configuration via config.yaml.

2. Kafka + Debezium (CDC)

Configuration de Kafka Connect & Debezium pour capturer les changements dans Postgres.

Diffusion des Ã©vÃ©nements CDC vers MinIO.

3. Orchestration avec Airflow

CrÃ©ation de DAGs pour :

Ingestion MinIO â†’ Snowflake (Bronze).

Planification des snapshots & chargements incrÃ©mentaux.

4. EntrepÃ´t de donnÃ©es Snowflake

Organisation en couches Bronze â†’ Silver â†’ Gold.

CrÃ©ation de schÃ©mas de staging pour lâ€™ingestion initiale.

5. Transformations DBT

ModÃ¨les de staging â†’ nettoyage et normalisation des sources.

ModÃ¨les de faits et dimensions â†’ crÃ©ation des marts.

Snapshots â†’ suivi historique des clients et comptes.

6. CrÃ©ation du Dashboard avec Power BI

ğŸ“Š Livrables finaux

Pipeline CDC automatisÃ©e de Postgres â†’ Snowflake

ModÃ¨les DBT (faits, dimensions, snapshots)

DAGs Airflow orchestrÃ©s

Jeu de donnÃ©es bancaires synthÃ©tiques pour dÃ©monstration

Dashboard Power BI pour le suivi en temps rÃ©el des donnÃ©es bancaires

<img src="images/dashboard.png" alt="Architecture" width="800"/>